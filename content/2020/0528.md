+++
date = '2020-05-28'
title = 'sedlex & menhir'
tags = ['ocaml', 'parser']
+++

这几天研究了下 ocaml 的 parser generator。
ocaml 里和 lex/yacc 对应的工具就叫 ocamllex/ocamlyacc，解析 ocaml 源码用的也是这套工具。
不过维护者有计划从 ocamlyacc 迁移到 menhir，后文就直接使用 menhir 了。
大部分现代语言都假定源码是 utf8 的方式编码，甚至支持用 emoji 之类的 unicode 作为变量名等。
ocaml 则是个异类，源码以 latin-1 编码。为 ocaml 服务的 ocamllex 自然也没有 utf8 支持。
后文会使用支持 unicode 的 sedlex 代替 ocamllex。

## sedlex

ocamllex 会先把 `lexer.mll` 编译成 `lexer.ml`，dune 里内置了 `(ocamllex lexer)` 指令来完成这个操作。
而 sedlex 则是以 ppx 的方式提供，内置的正则语法可以查看 [文档](https://github.com/ocaml-community/sedlex/blob/v2.1/README.md#lexer-specifications)。
整体来说，很容易上手，不需要像 ocamllex 那样单独学习一套语法。
除了语法，直接编写 ocaml 意味着周边工具配套完整，比如语法检查、代码格式化等。

```ocaml
module T = Token
let whitespace = [%sedlex.regexp? ' ' | '\t']
let newline = [%sedlex.regexp? '\n' | "\r\n" | '\r']
let rec scan lexbuf =
    match%sedlex lexbuf with
    | eof -> T.EOF
    | Plus whitespace -> scan lexbuf
    | newline -> Sedlexing.new_line lexbuf; scan lexbuf
    | ('#', Star (Sub (any, ('\n' | '\r')))) -> T.COMMENT (Sedlexing.Utf8.lexeme lexbuf)
    | _ -> assert false
```

上面就是一个简单的 sedlex lexer 了。

```ocaml
let rec parse (lexbuf : Sedlexing.lexbuf) =
    let revisedParser =
        MenhirLib.Convert.Simplified.traditional2revised Parser.main
    in
    let rec lexer () =
        let token = Lexer.scan lexbuf in
        let (start_p, end_p) = Sedlexing.lexing_positions lexbuf in
        (token, start_p, end_p)
    in
    revisedParser lexer
let parse_string (src : string) = parse (Sedlexing.Utf8.from_string src)
let parse_chan (src : in_channel) = parse (Sedlexing.Utf8.from_channel src)
```

和 menhir 配合的时候，需要像上面这样写点样板代码。
menhir 的 traditional parser 假设输入是 ocamllex 生成的 lexer，而 revised parser 则是接受一个 `() -> (token * start_p * end_p)`。sedlex 为此提供了 `lexing_positions` 方法。

再总结一下的话，sedlex 以 ppx 的方式提供，意味着它可以只是 lexer 的一部分，复杂的逻辑、状态都是可以用 ocaml 编写再组合，整个 lexer 的 debug 过程相对而言也更简单。
还有场景不知道怎么解析的话，可以翻一翻 facebook 为 flow 写的 [lexer](https://github.com/facebook/flow/blob/v0.125.1/src/parser/flow_lexer.ml)，JS 的词法解析应该足以给大部分场景提供参考了。

## menhir

menhir 的 [文档](http://gallium.inria.fr/~fpottier/menhir/manual.html) 很丰富，不过文档里没有的网上大概率也搜不到…
首先是从 `parser.mly` 生成 `parser.ml{,i}`，这个过程 dune 也内置了 `(menhir (modules parser) (flags --strict --explain))` 指令。
还有很多有趣的 flag，比如为状态转移生成 dot graph 之类的，还是看文档吧。

```ocaml
%{
module S = Syntax
%}

(* ---------- ---------- ---------- *)

%token EOF

(* constants *)
%token <string> STRING
%token <string> NUMBER

(* identifier and keyword *)
%token <string> ID
%token TRUE FALSE ON OFF
%token ANALYZE VERBOSE SKIP_LOCKED

(* operator *)
%token LEFT_PAREN "("
%token RIGHT_PAREN ")"
%token COMMA ","
%token SEMICOLON ";"

(* ---------- ---------- ---------- *)

%start <S.t list> main

%% (* ---------- ---------- ---------- *)

%public let plist(id) ==
  ~=loption(delimited("(", separated_nonempty_list(",", id), ")")); <>

(* ---------- ---------- ---------- *)

let boolean_true == TRUE | ON
let boolean_false == FALSE | OFF

(* ---------- ---------- ---------- *)

let table_and_columns := ~=separated_nonempty_list(",", table_and_column); <>
let table_and_column == name=table_name; columns=plist(column_name); { S.({name;columns}) }
let table_name == ~=ID; <>
let column_name == ~=ID; <>

(* ---------- ---------- ---------- *)

let main :=
  ~=stmts; EOF; <>
let stmts ==
  ~=list(stmt_with_sep); <>
let stmt_with_sep ==
  ~=stmt; nonempty_list(";"); <>
let stmt :=
  | ~=analyze_stmt; <>

(* ---------- ---------- ---------- *)

let analyze_stmt :=
  | ANALYZE; options=plist(analyze_option); tables=loption(table_and_columns); { S.ANALYZE({options;tables}) }
  | ANALYZE; VERBOSE; tables=loption(table_and_columns); { S.ANALYZE({options=[`VERBOSE(true)];tables}) }

let analyze_option ==
  | VERBOSE; ioption(boolean_true); { `VERBOSE(true) }
  | VERBOSE; boolean_false; { `VERBOSE(false) }
  | SKIP_LOCKED; ioption(boolean_true); { `SKIP_LOCKED(true) }
  | SKIP_LOCKED; boolean_false; { `SKIP_LOCKED(false) }
```

这个是我用来解析 SQL 的 parser，没有涉及到操作符优先级的部分，优先级这个可以先看文档提供的例子，下面针对上面的例子展开。

最开始 `%{ ... %}` 包围的部分是 ocaml 代码，可以放一些辅助函数。
之后是 token 定义，就是 `type token = EOF | STRING of string | ...` 换了个写法。
接着 start 指定了 parser 的入口以及返回的类型，也就是 `let main lexer : S.t list = ...`。
`%%` 分隔符之后，就正式进入 parser 了。

逗号分割的列表，这种模式太常见了，所以用 `%public` 写了一个辅助函数。
`let name :=` 定义一个新的模式。
`let name ==` 会把定义的模式给 inline 掉，这个可以写完 parser 再考虑。

很重要的一点是匹配后采取什么操作。
`let table_name == ~=ID; <>`  是 `let table_name == id=ID; { id }` 的缩写，这里 id 会是 token 定义的 string。`{ ... }` 里面是任意 ocaml 语句。

---

接下来是对 parser generator 的不满。

上面对 `boolean_true` 的定义是 `TRUE | ON`，这是不完整的。真正的应该是 `TRUE | ON | 1`，true/on 是关键字，而 1 是数字字面量。
menhir 里无法在 pattern 里对 `NUMBER(1)` 的内容做判断，只知道这是一个 number token，lexer 那边也不可能知道数字 1 此时应该算是 keyword 而不是 number。
我觉得这里是驱动的顺序错了。
这里是 parser 从 lexer 拿到一个 token，然后判断该进行什么操作。
正确的顺序应该是 parser 需要某种 token，然后 lexer 里判断后续的符号是否符合该 token 的语义。
翻了下 postgresql 的[实现](https://github.com/postgres/postgres/blob/REL_12_3/src/backend/parser/gram.y#L10584-L10587)，同样无法在 pattern 里准确定义，只能交给后续代码处理。

类似的问题也出现在 identifier/keyword 上，比如在 sql/js 之类的语言里，部分 keyword 在部分场景被视为 identifier。
parser generator 的 pattern 里只能匹配 token，意味着需要 identifier 的时候，可能需要添上需要 keyword token。比如 postgresql 的 [col_name_keyword](https://github.com/postgres/postgres/blob/REL_12_3/src/backend/parser/gram.y#L15315) 等。

---

就个人而言，再有解析的工作，大概不会选择 parser generator 了。
手写或者 parser combinator 都是不错的选择。
